	Мощность алфавита - N
		- полное число символов алфавита.

	Информационный вес символа алфавита - і
		- минимальная разрядность двоичного кода, требуемая для двоичного кодирования всех символов
			исходного алфавита
		- количество бит, занимаемых 1 символом.


		N = 2 в степени i


	Информационный объем сообщения - I
		- равен произведению количества символов в сообщении К на информационный вес символа алфавита і


		I = K*i


Чему равна сложность слова в вероятностном подходе?
	Логарифму вероятности слова со знаком минус

Как вычисляется вероятность слова в вероятностном подходе?
	Перемножением вероятностей букв, составляющих слово
	
Что является основной проблемой абсолютного определения сложности?
	Абсолютная сложность невычислима
	
Почему вычисление колмогоровской сложности невозможно?
	Программы, вычисляющие её, противоречат теоремам

Почему вероятностный подход используется в криптографии?
	Он помогает строить случайные последовательности

Как определяется комбинаторная сложность слова?
	Логарифмом мощности множества слов
	
Кто из ученых сформулировал теорему о существовании универсальной программы?
	Колмогоров

Что определяет сложность слова в алгоритмическом подходе?
	Минимальную длину кода слова относительно программы
	
Что изучается в рамках вероятностного подхода?
	Количество информации, связанное с исходом эксперимента
	
Каково значение функции h(р) в вероятностном подходе?
	Рассчитывает количество информации для исхода
	
Какие существуют три подхода к понятию сложности слова?
	Алгоритмический, комбинаторный, вероятностный
	
Какая теорема утверждает, что h(р) равна логарифму вероятности с минусом?
	Теорема Шеннона
	
Что характеризует эмпирическую вероятность слова?
	Частоту букв в слове
	
Что такое универсальная программа в алгоритмическом подходе?
	Программа, минимизирующая длину кода для любого слова
	
Какое утверждение верно для случайных последовательностей?
	Они должны быть сложными
	
Чему равна взаимная информация разбиений А и В?
	I(A, B) = H(A) - H(A|B)
	
Чему равно значение DA(PIQ), если Р(а) = Q(а) для всех событий?
	0
	
Что показывает неравенство обработки информации?
	Информация может только теряться
	
Как называется мера расхождения между двумя вероятностными распределениями?
	Дивергенция
	
Чему равна эмпирическая энтропия слова?
	H(A, Pr) = 1/|w| *I(w|Pr)
	
Что называется энтропией разбиения?
	Величина, вычисляемая как сумма произведений вероятностей событий на их логарифмы

Что обозначает формула DA(P|Q)?  Что обозначает формула DA(PIQ)?
	Меру расхождения между распределениями
	
Какое свойство имеет взаимная информация I(А, В)?
	Она симметрична
	
Какова верхняя граница энтропии Н(А, Р)?
	log k
	
Какая величина обладает свойствами метрики?
	dA(P, Q)
	
Как вычисляется расстояние р(А, В) между разбиениями?
	p(A, B) = H(A|B) + H(B|A)
	
Что является условием независимости разбиений А и В?
	H(A|B) = H(A)
	
Что такое вероятностное пространство?
	Множество событий с вероятностной мерой
	
Что определяет значение Н(АВ)?
	H(AВ) = H(A|B) + H(B)
	
Какая формула используется для вычисления условной энтропии Н(А|В)?
	H(A|B) = H(AB) - H(B)
	
Чему равно значение DA(PIQ), если P(а) = Q(а) для всех событий?
	0
	
Как определяется вектор стационарных вероятностей?
	п = Рп 

Как называется матрица, составленная из переходных вероятностей цепи Маркова?
	Стохастическая матрица
	
Что утверждает закон больших чисел для цепей Маркова?
	Средняя частота состояния сходится к стационарной вероятности

Как вычисляется вероятность перехода за п шагов в цепи Маркова?
	Рекуррентной формулой

Какие вероятности называются стационарными?
	Вероятности, не зависящие от времени

Какие вероятности используются для определения вектора стационарных вероятностей?
	Все возможные вероятности переходов

Что происходит с вероятностями переходов в непериодической цепи Маркова?
	Они стремятся к стационарному значению
	
Что утверждает эргодическая теорема?
	Непериодическая неразложимая цепь Маркова имеет стационарное распределение

Какая цепь Маркова называется неразложимой?
	В которой из любого состояния можно попасть в любое другое

Как определяется период состояния в цепи Маркова?
	Это наибольший общий делитель числа шагов для возвращения в состояние

Какая цепь Маркова называется непериодической?
	В которой период равен единице

Что является условием стохастической матрицы?
	Сумма элементов каждой строки равна 1

Что такое закон больших чисел?
	Среднее значение случайных величин стремится к математическому ожиданию

Что является условием периодической цепи Маркова?
	Все состояния имеют период больше 1

Как называется случайная последовательность, где вероятность исхода зависит только от предыдущего состояния?
	Цепь Маркова

Как называется автоматная модель с единственным состоянием?
	Модель Бернулли

Как определяется конечный автомат?
	Граф с вершинами и дугами, помеченными буквами алфавита

Какие состояния выделяются в конечном автомате?
	Входные и выходные

Чему равна вероятность слова в автоматной модели?
	Сумме вероятностей всех путей, соответствующих слову

Что определяет вероятность пути в графе автомата?
	Произведение вероятностей дуг, составляющих путь

Что является основной задачей при выборе модели источника сообщений?
	Выбор модели, максимально соответствующей тексту 

Что называется детерминированным автоматом?
	Автомат, где из одной вершины не выходит двух дуг с одинаковыми пометками

Какой язык порождается конечным автоматом?
	Регулярный

Что называется контекстной моделью?
	Модель, где состояние однозначно определяется словом

Что описывает модель источника сообщений?
	Вероятности слов, порождённых источником




Как вычисляется энтропия марковского источника?
	Как средневзвешенная энтропия состояний
	
Как определяется эмпирическая энтропия слова?
	Как минус логарифм его вероятности

Что такое источник сообщений?
	Пара из алфавита и распределения вероятностей

Что такое марковский источник?
	Источник, где вероятность следующего символа зависит только от текущего состояния

Что показывает неравенство для эмпирической энтропии источника Бернулли?
	Она сходится к энтропии в среднем

Что показывает неравенство Чебышёва для эмпирической энтропии?
	Вероятность отклонения от истинной энтропии уменьшается с увеличением длины

Что характеризует стационарный марковский источник?
	Его начальные вероятности равны стационарным

Какой источник называется стационарным?
	У которого вероятности не зависят от времени

Что отражает энтропия источника сообщений?
	Минимальное количество бит на кодирование одного символа

Как определяется вероятность слова в марковской модели? 
	Как произведение вероятностей букв в их состояниях
	
Что утверждает эргодическая теорема для марковских источников?
	Энтропия марковского источника существует и выражается через стационарные вероятности

Чему равна энтропия источника Бернулли?
	Энтропии его алфавита для любой длины последовательности

Какой метод используется для вычисления наиболее вероятного пути в марковских моделях?
	Алгоритм Витерби

Что такое арифметическое кодирование?
	Кодирование, использующее деление интервалов вероятностей

Какое кодирование называется префиксным?
	Кодирование, где ни одно кодовое слово не является префиксом другого

Чем отличается кодирование Шеннона-Фано от кодирования Хаффмана?
	Использует деление алфавита на части с равными вероятностями

Что характеризует побуквенное кодирование?
	Каждый символ кодируется независимо от других

Какое свойство имеет кодирование Хаффмана?
	Оно всегда оптимально для любого источника Бернулли

Что такое стоимость кодирования?
	Средняя длина кодовых слов, взвешенная по вероятностям

Что называется избыточностью кодирования?
	Разница между средней длиной кода и энтропией источника

Как кодируются натуральные числа в методе Элайеса?
	Добавлением ведущих нулей и длины числа

Что является необходимым условием кодирования?
	Обратимость отображения и частичная вычислимость

Что утверждает теорема Шеннона о кодировании?
	Существует префиксное кодирование с нулевой предельной избыточностью

Что обеспечивает префиксность кодирования?
	Возможность декодирования по частям

Каким свойством обладает нумерационное кодирование?
	Его предельная избыточность равна нулю

Какое множество называется разделимым?
	Множество, где любая последовательность слов разбивается на них однозначно

Что такое кодирование?
	Инъективное отображение из множества слов в двоичные последовательности

Какое свойство выполняется для функции сложности LZ относительно слова?
	Она монотонно возрастает при добавлении символов

Какое преимущество имеет схема Лемпела - Зива?
	Независимость от длины алфавита
	Высокая скорость выполнения алгоритма
	Минимальная скорость кодирования

Что утверждает теорема о предельной избыточности схемы конкатенации?
	Она стремится к нулю для источников Бернулли

Что называется суффиксной сложностью слова?
	Число подслов, выделенных при разбиении слова

Какой алгоритм используется для вычисления сложности схемы Лемпела - Зива?
	Линейный алгоритм

Как кодируются подслова в схеме Лемпела - Зива?
	С помощью троек чисел, описывающих структуру подслова
	Посредством энтропийного кодирования
	Используются только буквенные обозначения

Что кодируют тройки чисел в схеме конкатенации?
	Разницу, минимальный индекс и порядок конкатенации

Что означает "правильная" схема конкатенации?
	Схема, в которой соблюдается порядок добавления слов

Что обеспечивает схема Лемпела - Зива?
	Асимптотическую избыточность, равную нулю

Что утверждает теорема Лемпела - Зива?
	Предельная избыточность кодирования для стационарных источников равна нулю

Что представляет собой модификация LZ77?
	Применение динамического словаря для кодирования
	Использование троек чисел для кодирования
	Упрощение схемы разделения на подслова

Что такое схема Лемпела - Зива?
	Алгоритм разбиения слова на подслова с учётом их повторяемости

Для чего применяется схема Лемпела - Зива в практике?
	Для сжатия данных и архивирования

Какая основная цель схемы конкатенации?
	Минимизация длины кодирования
	Упрощение построения графов
	Максимизация длины подслов

Как определяется аддитивная сложность слова?
	Как минимальная длина схемы конкатенации слова











